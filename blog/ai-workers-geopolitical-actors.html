<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>AI Workers Are Becoming Geopolitical Actors — Sydney Reis</title>

  <!-- Retro fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Press+Start+2P&family=VT323&display=swap" rel="stylesheet">

  <style>
    :root{
      --bg: #e9edf5;
      --panel: #f6f7fb;
      --accent: #000080;
      --ink: #001;
      --muted: #666;
      --bevel1: #fff;
      --bevel2: #bfc7d9;
      --card-bg: #fff;
      --content-ink: #111;
    }

    html,body{height:100%;margin:0}
    body{
      font-family: 'VT323', monospace;
      background: linear-gradient(180deg, var(--bg), #f0f3fb 60%);
      color: var(--ink);
      padding:28px;
      -webkit-font-smoothing:antialiased;
      -moz-osx-font-smoothing:grayscale;
    }

    .wrapper{max-width:920px;margin:0 auto}

    .window{
      background: var(--panel);
      border: 1px solid var(--bevel2);
      box-shadow: 3px 3px 0 rgba(0,0,0,0.06);
      border-radius:6px;
      overflow:hidden;
      margin-bottom:20px;
    }

    .titlebar{
      display:flex;
      align-items:center;
      gap:12px;
      padding:10px 12px;
      background: linear-gradient(180deg,#dfe6f6,#e9eefc);
      border-bottom: 1px solid var(--bevel2);
      box-shadow: inset 0 1px 0 var(--bevel1);
      font-family: 'Press Start 2P', monospace;
      color: var(--accent);
      font-size:0.95rem;
      letter-spacing:1px;
    }

    .controls{display:flex;gap:8px;margin-right:6px}
    .control{
      width:12px;height:12px;border-radius:2px;display:inline-block;text-align:center;line-height:12px;font-size:9px;
      box-shadow: inset 0 1px 0 rgba(255,255,255,0.6), 0 1px 0 rgba(0,0,0,0.05);
      background: linear-gradient(180deg,#fff,#ddd);
    }
    .control.close{ background: linear-gradient(180deg,#ffd6d6,#ffbdbd); }
    .control.max{ background: linear-gradient(180deg,#fff9c8,#fff2a6); }
    .control.min{ background: linear-gradient(180deg,#d6f7d6,#bfeebb); }

    .title{flex:1;font-size:0.9rem;text-transform:uppercase}
    .title a{font-family:'Press Start 2P',monospace;color:var(--accent);text-decoration:none}

    .tiny-nav{font-size:0.78rem;color:var(--muted);display:flex;gap:10px;align-items:center}
    .tiny-nav a{
      color:var(--muted);
      text-decoration:none;
      padding:6px 8px;
      border-radius:4px;
      background:#fff;
      border:1px solid var(--bevel2);
      box-shadow:inset 0 1px 0 var(--bevel1);
      font-family:'Press Start 2P',monospace;
    }

    .window-body{padding:18px}

    /* Article / content */
    .post{
      background: var(--card-bg);
      border: 1px solid var(--bevel2);
      padding:20px;
      border-radius:6px;
      color: var(--content-ink);
    }

    .post-title{
      font-family: 'Press Start 2P', monospace;
      color: var(--accent);
      font-size:1.05rem;
      margin:0 0 10px 0;
      letter-spacing:0.6px;
    }

    .meta{ color: var(--muted); margin-bottom:14px; font-size:0.9rem; }

    .content p, .content h2 {
      font-family: 'VT323', monospace;
      color: var(--content-ink);
      line-height:1.6;
      margin:0 0 1rem 0;
      font-size:16px;
    }

    .content h2{
      margin-top:1.1rem;
      font-family:'Press Start 2P',monospace;
      color:var(--accent);
      font-size:0.95rem;
      margin-bottom:0.6rem;
      letter-spacing:0.6px;
    }

    .back{
      display:inline-block;
      margin-top:18px;
      text-decoration:none;
      padding:8px 10px;
      border-radius:4px;
      background:#fff;
      color:var(--accent);
      border:1px solid var(--bevel2);
      box-shadow:inset 0 1px 0 var(--bevel1);
      font-family:'Press Start 2P',monospace;
      font-size:0.78rem;
    }
    .back:hover{ background: linear-gradient(180deg,#fff8d9,#fff2a6); }

    @media (max-width:640px){
      .window-body{padding:14px}
      .content p { font-size:15px; }
    }

    a:focus{ outline:3px solid rgba(0,0,160,0.12); outline-offset:3px; }
  </style>
</head>

<body data-active="blog">
  <div class="wrapper">
    <div class="window" role="article" aria-label="Blog post">
      <div class="titlebar">
        <div class="controls" aria-hidden="true">
          <span class="control min">•</span>
          <span class="control max">◻</span>
          <span class="control close">✕</span>
        </div>

        <!-- Title (links to blog index) -->
        <div class="title"><a href="index.html">Blog</a></div>

        <!-- small nav: Home + Posts -->
        <div class="tiny-nav" aria-hidden="false">
          <a href="../index.html">Home</a>
          <a href="index.html">Posts</a>
        </div>
      </div>

      <div class="window-body">
        <article class="post">
          <h1 class="post-title">AI Workers Are Becoming Geopolitical Actors, and it Matters for the Future of AI Governance</h1>

          <div class="meta">By Sydney Reis · Responsible Technology Institute, University of Oxford · 2025</div>

            <p>
              This post is based on a paper for the 2025 NeurIPS workshop on Algorithmic Collective Action.
              The full paper and its citations can be found 
              <a href="https://arxiv.org/abs/2511.17331" target="_blank" rel="noopener noreferrer">here</a>.
            </p>
          
            <h2>Why AI Governance Alone Isn’t Enough</h2>
            <p>We talk a lot about regulating Artificial Intelligence (AI), but far less about the political power of the people and organisations that actually build, promote, and proliferate it. As AI systems have grown more powerful, so have the companies that develop them. These companies now influence national security, foreign policy, and even concepts of national sovereignty. AI companies are also increasingly finding themselves at the center of the so-called “AI arms race”, which is normally framed between the US and China. Meanwhile, the theory of International Political Economy (IPE) shows that governments often find themselves relying on these firms rather than regulating them.</p>

            <p>According to IPE, states are often incentivized to remove barriers for powerful corporations if those corporations can help advance national strategic interests through their resources or innovations. When it comes to AI, this means that many national governments must contend with mitigating unintended AI harms and acieving geopolitical advantage through chokepoints and technological supremacy.</p>

            <p>If you’ve ever wondered why AI governance is uneven, slow, or in some cases, deprioritized, the geopolitical environment is partly to blame. But this doesn’t mean that better, safer, more responsible AI can't be built. Nor does it mean that AI governance isn’t the answer. To be absolutely clear, AI governance is necessary. However, in this post, I contend that we need to look beyond just legislation and consider engaging a different set of actors. This is the people that build and deploy AI systems come in. From here on out, I will refer to them as AI workers.</p>

            <h2>AI Workers as Geopolitical Actors</h2>
            <p>We tend to imagine geopolitics as something governments engage in, not something software engineers or machine learning researchers influence. But I, and many others, argue that this paradigm should be rethought in the age of rapid power acquisition by AI and other technology companies.</p>

            <p>AI workers sit in uniquely consequential positions. They design, train, and deploy the models shaping international AI competition, hold oftentimes scarce and highly mobile technical skills, encode assumptions and values into the systems they build, and possess political agency, which many have engaged in on different occassions.</p>

            <p>From Google employees walking out over Project Maven to workers protesting military cloud contracts, AI labour has demonstrated geopolitical will. Beyond engaging in resistance efforts, AI workers are also becoming geopolitical actors simply by virtue of their power and influence over the systems they contribute to creating, while their technical artefacts contribute to the growth of companies that now rival states in terms of their resources. As AI companies increasingly shape national technology, military, and diplomatic strategy, workers’ decisions regarding what to build, where to focus their attention and talents, what to refuse, and what to question matters more than ever.</p>

            <h2>A Gap in AI Governance</h2>
            <p>Most proposals designed to mitigate AI’s risks focus on the development of top-down interventions such as international treaties, national regulations, corporate governance guidelines, and safety standards. These types of governance are all important and necessary. But, given state incentives, I do not believe that they are enough. There are other, arguably overlooked ways to complement AI governance and other top down efforts that merit more attention and resources.</p>

            <p>As long as states are incentivized to pursue geopolitical advantage, then governance mechanisms alone are not enough to ensure that the big, aspirational words that we like to see around AI are actually operationalised; words like ethical, responsible, fair, safe, and secure. That is where local, bottom-up approaches come in, and where Algorithmic Collective Action (ACA) becomes an interesting use-case.</p>

            <h2>How AI Workers Can Contribute to Algorithmic Collective Action</h2>
            <p>ACA research typically looks at platform workers like artists, delivery drivers, and content moderators, some of whom may be marginalized in several ways, like being from the Global South or facing precarious labour conditions. Using algorithms, these groups organize to create better or fairer working conditions for themselves: hence the term Algorithmic Collective Action.</p>

            <p>However, AI workers that are arguably more privileged, such as researchers, engineers, and technical staff within corporate or university labs, have not yet been featured in the emerging discipline of ACA. Science and Technology Studies (STS) has long recognized how the values of technology makers are reflected in technologies themselves. From this lens, it becomes impossible to ignore the role of AI researchers and engineers because of how they as people influence model development. Their collective actions can shape entire technological trajectories, and their workplaces have real geopolitical stakes and consequences. And unlike platform workers, AI workers sometimes enjoy mobility, bargaining power, and public visibility, all of which can make collective action that much easier to organize.</p>

            <h2>A Participatory Design Approach to Engaging AI Workers</h2>
            <p>If AI workers are geopolitical actors, how do we support them in acting responsibly or encouraging geopolitical consciousness? One path forward comes from Participatory Design (PD), a methodology rooted in empowering workers to shape technologies and practices that affect their lives. PD traditionally focuses on giving underrepresented groups a voice in technology design processes, but the practice could be applied to any group with specific needs and interests.</p>

            <p>For instance, PD could be used to help AI workers reflect on the geopolitical implications of their work, co-create tools and practices that support ethical decision-making, or build shared understanding and critical awareness of the structural or geopolitical influences of their technologies (the effects of which can be notoriously difficult to imagine!). PD itself is a bottom-up approach and a useful complement or alternative to governance. It doesn’t dictate or purport to have all the solutions. Rather, the approach is guided by an ethos of uncovering solutions with the people directly involved.</p>

            <h2>Better AI Needs a Bottom-Up Layer</h2>
            <p>The point isn’t to romanticize tech workers, nor is it to make them shoulder the burden of weak, politicised, or insufficient regulation. But they do have relative agency, insider knowledge, and are the architects of increasingly globally consequential systems. Any realistic strategy for safer, more just, more responsible, or just better AI needs to include them. Bottom-up interventions, from PD-informed practices to ACA, can and should complement top-down governance.</p>

          </div>

          <div style="margin-top:18px">
            <a class="back" href="index.html">← Back to posts</a>
            <a class="back" href="../index.html" style="margin-left:8px">← Home</a>
          </div>
        </article>
      </div>
    </div>
  </div>
</body>
</html>
